########################### INSTALL ON BARE MACHINE ######################
#ZOOKEEPER
$ cat > /usr/local/zookeeper/conf/zoo.cfg << EOF
> tickTime=2000
> dataDir=/var/lib/zookeeper
> clientPort=2181
> EOF
$ /usr/local/zookeeper/bin/zkServer.sh start

#KAFKA Broker
$/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties

#create a topic
$ /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

#get info about the topic
$ /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test

#produce a message to the topic
$ /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

#consume a message from the topic
$ /usr/local/kafka/bin/kafka-console-consumer.sh --boostrap-server localhost:9092 --topic test --from-beginning


########################## SETTINGS #########################
#Server setting is into server.properties from kafka/config folder

#By default kafka will create a topic when: producer start to write, consumer starts to read, client request metadata
#to disable this use auto.create.topics.enable=false

#Number or partitions of a topic could only increase it will never decrease
#Number of partition is computing based on throughput of the servers
#Messages are retain using : log.retention.hours, log.retention.minutes and log.retention.ms by default is 168h so 1 week
#If more settings is defined then he smaller value take precedence
#log.retention.bytes are defined per partion not per system
#The message is removed when the first condition is met: bytes or time
#log.segment.bytes and log.segment.ms is on segment and when one is meet then the segment with messages are considered for retention policy
#message.max.bytes is the maximum size of the message the default is 1M this should be colaborated with fetch.message.max.bytes  from clients
#For AWS typical EC2 instances are m4 or r3 to hold kafka
# Partitioner is set using property partitioner.class

#################################################################
# Avro could be used for serializer/deserializer using https://avro.apache.org/docs/1.7.7/spec.html#Schema+Resolution
# The best when use avro is put the schema into the schema registry like https://github.com/confluentinc/schema-registry
# to use avro with schema registry set the following properties
# props.put("key.serializer","io.confluent.kafka.serializers.KafkaAvroSerializer");
# props.put("value.serializer","io.confluent.kafka.serializers.KafkaAvroSerializer"); 1
# props.put("schema.registry.url", schemaUrl);
# to use schema:
# Schema.Parser parser = new Schema.Parser();
# Schema schema = parser.parse(schemaString);
# GenericRecord customer = new GenericData.Record(schema);

############# PRODUCER ########################################
# key.serializer sould implement org.apache.kafka.common.serialization.Serializer this is need even you send only values
#type of sending:
# fire and forget - send
# synchronous send - send.get
# async-send - send with callback which is comming after broker response
# send is done in separate thread
# acks=1 the producer will receive a success response from the broker when the leader replica receive the message. The message can still be lost if the leader crasches and a replica without this message gets elected as the new leader.
# acks=all the producer will receive a success response from the broker once all in-sync replicas received the message.
# compression.type=<snappy,gzip,lz4>
# retry.backoff.ms=<ms between retries default 100>
# batch.size=<memory in bytes> when the batch is full the messages from the batch will be send (it is used when multiple records are sent to the same partition).
# linger.ms control the time between sending batch messages. Default is 0 so the producer will send messagea as soon as there is a sender thread available to send them.
# client.id
# max.inflight.requests.per.connection=1 will guarantee that messages will be written to the broker in the order in which they were sent, even when retries occur. This is in fact: how many messages the producer will send to the server without receiving responses.
# timeout.ms
# request.timeout.ms
# metadata.fetch.timeout.ms
# max.block.ms
# max.request.size default is 1M and it caps both the size of a single message and the number of messages that a producer can send in one request. the server should have the same value in message.max.bytes environment
# receive.buffer.bytes and send.buffer.bytes are buffers for tcp and if is set to -1 then the OS default will be use. Increase the value when producer and consumers are in different datacenters or when network have higher latency and lower bandwidth.
# in.flight.requests.per.session=1 is set to be sure that is order of send messages is preserved.
# KAFKA preservers the order of the messages within a partition.
# All messages with same key will go in the same partition.
# If the key is null and default partitioner is used then the round robin algorithm will be use to load balance the data between partitions.
# The mapping of keys to parttions is consistent only as long as the number of partitions in a topic does not change.
# the hash is kafka implementation : Math.abs(Utils.murmur2(keyBytes)) % numPartitions)
############# CONSUMER ########################################
# key.deserializer sould implement org.apache.kafka.common.serialization.Deserializer

#get the list of consumer groups
$ kafka-consumer-groups  --bootstrap-server localhost:9092 --list

# get the list of consumer groups by topic
$ kafka-consumer-groups  --bootstrap-server localhost:9092 --describe --group <GROUP_NAME>

#delete a consumer group
$ kafka-consumer-groups --bootstrap-server localhost:9092 --delete --group <GROUP_NAME>

#if we add more consumers into a consumer group than the partitions then the remaining consumers will get no data.
#we could have more consumers than the partitions if they are part of different consumer groups.
# If you are using a new version afetr 0.10.1 and need to handle records that take longer to process, you simply need to tune max.poll.interval.ms so it will handle longer delays between polling for new records.
# Subscribing to mutiple topics using a regular expression is most commonly used in application that replicate data between Kafka and another system.
# When you use regular expresion if a new topic is created with a matched name then the rebalance will happen and the cunsumer will start consume from the new topic.
#you cand't  have multiple consumers that belong to the same group in one thread and you can't have one consumer in multiple threads. Each consumer has to have his own thread. Normally you wrap consumer into an object and use ExecutorService to run them.

### Parameters for Consumer
# fetch.min.bytes if a broker receives a request for records from a consumer but the new records amount to fewer bytes, the broker waits until more messages are available
# fetch.min.ms=500 is the default tell broker to wait until it has enough data to send before responding to the consumer
# max.partition.fetch.bytes default is 1M it controls the maximum number of bytes the server will return per partition.
# session.timeout.ms default is 10 second. This is the amount of time a consumer can be out of contact with the brokers while still considered alive. After timeout expire the group coordinator will trigger a rebalance of the consumer this is colose relate to next one:
# heartbeat.interval.ms constrols how frequently the consumer poll will send a heartbeat to the group coordinator. This should be 1/3 from sesssion.timeout.ms
# auto.offset.reset the default is "latest" which means that lacking a valid offset the consumer will start reading from the newest records. Alternative is "earliest" when the consumer will read all the data in the partition.
# enable.auto.commit default true you have to control also auto.commit.interval.ms
# partition.assignment.strategy the default is org.apache.kafka.clients.consumer.RangeAssignor other option is : org.apache.kafka.clients.consumer.RoundRobinAssignor
# client.id
# max.poll.records is the maximum number of records that a single call to poll() will return
# receive.buffer.bytes and send.buffer.bytes if the value -1 then the OS defaults will be used.

###### other things for consumer
# the action of updating the current position in the partition is called commit
# if the committed offset is smaller than the offset of the last message the client actually processed, the messages between the last processed offset and the commited offset will be processed twice.
# it he commited offset is larger than the offset of the last message the client actually processed, the messages between the last processed offset and the committed offset will be missed by the consumer group.
# enable.auto.commit=true then every 5seconds(set by auto.commit.interval.ms) the consumer will commit the largest offset received. Whenever you poll the consumer checks if is time to commit. close() will commits offsets automatically.
# auto.commit.interval.ms the default si 5 seconds
# commitAsync will not retry as the commitSync does.
# commitAsync could have a callback implemented OffsetCommitCallback
# for async to get commit order right is to use a monotonically increasing sequence number. Increase the sequence number evry time you commit and add the sequence number in callback.
# use sync before closing the consumer if you want to be sure that the commit succeeds.
# use async with offset if you want to commit just a part of the records
#